{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO712egXeP1COiCsxfh6ntO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajBhadani/GHG_Emission_Prediction/blob/main/Green_House_Gas_Emission_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Supply Chain Emissions Modeling Using Industry and Commodity Data (2010â€“2016)**"
      ],
      "metadata": {
        "id": "YI4FKHThNJjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement:\n",
        "\n",
        "You have annual supply chain emission data from 2010â€“2016 categorized into industries and commodities. The goal is to develop a regression model that can predict the Supply Chain Emission Factors with Margins based on descriptive and quality metrics (substance, unit, reliability, temporal/geographical/technological/data collection correlations, etc.)"
      ],
      "metadata": {
        "id": "MXL1U9qfNQK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸŒ± Greenhouse Gas Emission Prediction Project**"
      ],
      "metadata": {
        "id": "NfYfD36LNkbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Goal:\n",
        "To analyze and predict greenhouse gas (GHG) emissions from various U.S. industries and commodities using the official dataset from data.gov."
      ],
      "metadata": {
        "id": "hyo4JbtHNxbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source:\n",
        "Supply Chain Greenhouse Gas Emission Factors"
      ],
      "metadata": {
        "id": "L8EshKNoN1W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tools: Python, Pandas, Scikit-learn, Matplotlib, Seaborn"
      ],
      "metadata": {
        "id": "UmhVCk-zN4M_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ“‚ Dataset Overview**"
      ],
      "metadata": {
        "id": "4ro8Ia5AN7k5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains supply chain emission factors associated with various U.S. industries and commodities."
      ],
      "metadata": {
        "id": "b3uUS-adOMlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Columns:**\n",
        "\n",
        "*   Code: Industry classification code\n",
        "*   Industry_Name: Name of the industry\n",
        "*   Commodity: Item or commodity name\n",
        "*   GHG_Emissions_kgCO2e: GHG emissions per unit (kg *   CO2 equivalent)\n",
        "*   Units: Measurement units (e.g., [kg/2018 USD, purchaser price])"
      ],
      "metadata": {
        "id": "WbL8howeOcsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ§¹ Data Preprocessing**"
      ],
      "metadata": {
        "id": "UjpDjZNiUQWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps:**\n",
        "\n",
        "* Handle missing values\n",
        "* Convert units where needed\n",
        "* Encode categorical features\n",
        "* Normalize/scale numeric columns"
      ],
      "metadata": {
        "id": "1leS9lK4UYxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ¤– Model Building & Evaluation**"
      ],
      "metadata": {
        "id": "IS858mbVXL_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We aim to predict `GHG_Emissions_kgCO2e` using regression models.\n",
        "\n",
        "**Models to try:**\n",
        "\n",
        "* Linear Regression\n",
        "* Random Forest\n",
        "* Evaluation Metrics:\n",
        "\n",
        "**Evaluation Metrics:**\n",
        "\n",
        "* RMSE (Root Mean Squared Error)\n",
        "* MAE (Mean Absolute Error)\n",
        "* RÂ² Score\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "* Step 1: Import Required Libraries\n",
        "* Step 2: Load Dataset\n",
        "* Step 3: Data Preprocessing (EDA+Cleaning+Encoding)\n",
        "* Step 4: Training\n",
        "* Step 5: Prediction and Evaluation\n",
        "* Step 6: Hyperparameter Tuning\n",
        "* Step 7: Comapartive Study and Slecting the Best model"
      ],
      "metadata": {
        "id": "r5nhssfUXUil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Import Required Libraries**"
      ],
      "metadata": {
        "id": "vU_KDSkfZUBE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKOu6jaqMhqD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Load Dataset**"
      ],
      "metadata": {
        "id": "OzzeUoCzZxBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the Excel file\n",
        "excel_file = 'SupplyChainEmissionFactorsforUSIndustriesCommodities.xlsx'  # Replace with actual path\n"
      ],
      "metadata": {
        "id": "fgXyv58SZtNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the range of years to process\n",
        "years = range(2010, 2017)"
      ],
      "metadata": {
        "id": "Hkp7gdez0j3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing an element from the 'years' range (this line can be removed as it's just for inspection)\n",
        "years[2]"
      ],
      "metadata": {
        "id": "xuZ6oes3Z2hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data for the first year from the 'Commodity' sheet\n",
        "df_1 = pd.read_excel(excel_file, sheet_name=f'{years[0]}_Detail_Commodity')\n",
        "# Display the first few rows of the loaded DataFrame\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "UEMi9RuVaJXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data for the first year from the 'Industry' sheet\n",
        "df_2 = pd.read_excel(excel_file, sheet_name=f'{years[0]}_Detail_Industry')\n",
        "# Display the first few rows of the loaded DataFrame\n",
        "df_2.head()"
      ],
      "metadata": {
        "id": "Vo_JKId1xHzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store DataFrames from each yea\n",
        "all_data = []\n",
        "\n",
        "# Loop through each year in the defined range\n",
        "for year in years:\n",
        "    try:\n",
        "        # Load data from 'Commodity' and 'Industry' sheets for the current year\n",
        "        df_com = pd.read_excel(excel_file, sheet_name=f'{year}_Detail_Commodity')\n",
        "        df_ind = pd.read_excel(excel_file, sheet_name=f'{year}_Detail_Industry')\n",
        "\n",
        "\n",
        "        # Add a 'Source' column to indicate whether the data is from 'Commodity' or 'Industry'\n",
        "        df_com['Source'] = 'Commodity'\n",
        "        df_ind['Source'] = 'Industry'\n",
        "        # Add a 'Year' column to identify the year of the data\n",
        "        df_com['Year'] = df_ind['Year'] = year\n",
        "\n",
        "        # Clean up column names by removing leading/trailing whitespace\n",
        "        df_com.columns = df_com.columns.str.strip()\n",
        "        df_ind.columns = df_ind.columns.str.strip()\n",
        "\n",
        "        # Rename specific columns for consistency across data sources\n",
        "        df_com.rename(columns={\n",
        "            'Commodity Code': 'Code',\n",
        "            'Commodity Name': 'Name'\n",
        "        }, inplace=True)\n",
        "\n",
        "        df_ind.rename(columns={\n",
        "            'Industry Code': 'Code',\n",
        "            'Industry Name': 'Name'\n",
        "        }, inplace=True)\n",
        "\n",
        "        # Concatenate the commodity and industry data for the current year and append to the list\n",
        "        all_data.append(pd.concat([df_com, df_ind], ignore_index=True))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing year {year}: {e}\")"
      ],
      "metadata": {
        "id": "Bl6HDYfRxU5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing an element from the list of DataFrames (this line can be removed as it's just for inspection)\n",
        "all_data[3]"
      ],
      "metadata": {
        "id": "sDZu2BwWxbHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of DataFrames in the list (this line can be removed as it's just for inspection)\n",
        "len(all_data)"
      ],
      "metadata": {
        "id": "Wnsue3k0xfEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all DataFrames in the 'all_data' list into a single DataFrame\n",
        "df = pd.concat(all_data, ignore_index=True)\n",
        "# Display the first 10 rows of the combined DataFrame\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "Ec6isLcZxhhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows in the concatenated DataFrame (this line can be removed as it's just for inspection)\n",
        "len(df)"
      ],
      "metadata": {
        "id": "lT7zionuxlaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Data Preprocessing**"
      ],
      "metadata": {
        "id": "bt2ye7OAxsvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the column names of the combined DataFrame (this line can be removed as it's just for inspection)\n",
        "df.columns # Checking columns"
      ],
      "metadata": {
        "id": "gEGXN5ppxpxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in each column of the DataFrame\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "P_I__bfHxwnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FBqIjrMNx0uZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}